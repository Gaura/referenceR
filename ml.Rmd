Here is a guide to using caret package in predictive modelling: https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf

It is a useful package that consists of functions that unify predictive models from different packages.
It contains functions to do basic stuff like train test split in R.

Setup
```{r setup}
library(kernlab)
library(caret)
library(ISLR)
library(ggplot2)
library(Hmisc) # cut function for breaking data into groups
library(gridExtra)
```
## Intro and exploration

Creat data split
```{r}
?createDataPartition #shows up other useful functions as well
data("spam")
train <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[train,]
testing <- spam[-train,]
```
This function creates a training model and the performance measured is calculated based on resampling measure bootstrap
```{r}
model <- train(type ~ ., data = training, method = "glm")
model$finalModel # to view the final model
prediction <- predict(model,newdata= testing)
prediction
confusionMatrix(prediction,testing$type)
```
The train function comes with other bunch of arguments that might prove to be useful, for example it has metric argument to evalute the model performance, They are
1. For continous y
      - RMSE (default)
      - R-squared
2. For indicator y
      - Accuracy
      - Kappa
To further control the parameters of the train function, we can use trainControl function
```{r}
?trainControl
args(trainControl)
```
featurePlot in caret package to create a plot of the features
```{r}
data(Wage)
trainSamples <- createDataPartition(Wage$wage,p=0.7,list = FALSE)
trainData <- Wage[trainSamples,]
testData <- Wage[-trainSamples,]
featurePlot(x=trainData[,c("age","education","jobclass")],y=trainData$wage,plot = "pairs")
```
visualize trend, there seems to be positive cor b/w education and wages
```{r}
qp <- qplot(x = age, y = wage, data = trainData, color = education)
qp + geom_smooth(method = "lm",formula = y ~ x)
```
We can break the age into categorical variables to see the relationship between wages and age clearly.
One thing that we can do after the boxplot is to add points on the top of it so that we can see if the number of points are large in each set, otherwise if the points are not plotted we may not know
if the change is real or artificial because of change in sample size
```{r}
cutWage <- cut2(trainData$wage,g=3)
table(cutWage)
p1 <- qplot(cutWage,age,fill=cutWage,data=trainData,geom = c("boxplot"))
p2 <- qplot(cutWage,age,fill=cutWage,data=trainData,geom = c("boxplot","jitter"))
grid.arrange(p1,p2,ncol=2)
```
Now let us see how how the wage classes are distributed among the education categories
```{r}
t1 <- table(cutWage,trainData$education)
t1
prop.table(t1,1) # 1 is margin
```
This shows that 34% of high wage jobs are held by college grads followed by adv degree holders with 30% of the jobs

Let us check the same information visually using density plots
```{r}
qplot(wage,colour=education,data = trainData, geom = "density",ylab = "density")
```
This density plot is like prop.table but along the columns, it shows that adv degree holders have higher density at higher end of wages but their number may not be the highest, it is important to note that density is not the same as the numbers but is proportion within each education category

MAKE YOUR PLOTS ONLY IN THE TRAINING DATA
DO NOT USE THE TEST DATA FOR EXPLORATION

## Pre-processing

Pre processing is sometimes necessary because the variables might not be in suitable distribution for model, for example, the variable can be highly skewed with high standard deviation.
```{r}
hist(training$capitalAve,breaks = 100)
# Average number of capital letters is a highly skewed variable
mean(training$capitalAve)
sd(training$capitalAve)
```
The mean is around 5 and sd is 35, we can standardize it by substracting the mean and dividing by standard devation
```{r}
trainCapitalAveS <- (training$capitalAve - mean(training$capitalAve))/sd(training$capitalAve)
mean(trainCapitalAveS)
sd(trainCapitalAveS)
```
It is important to note that while applying the model to the test set, we can only use the parameters we estimated from the training set. So for standardization, we would use the mean and
standard deviation from the train set.

The same thing as above can be done using the preProcess function of the caret package
```{r}
# 58 is type column spam or not
preObj <- preProcess(training[,-58], method = c("scale","center"))
trainCapitalAveS <- predict(preObj,training[,-58])$capitalAve
# the same can be applied on the test data
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
```
Pre-processing can be done while training the model as well
```{r}
model <- train(type ~ ., data = training, preProcess=c("center","scale"), method = "glm")
model
```
scale and centre takes care of skewed or biased transforms but in case you want to transform your data to be like a normal distribution box-cox transformation can be used. Since, some models have normality assumption on the features, this might be useful.
```{r}
#First let us look at the distribution with standardization
hist(trainCapitalAveS,breaks = 100)
#It looks the same but with less variability
preObj <- preProcess(training[,-58],method = "BoxCox")
trainCapitalAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2))
hist(trainCapitalAveS,breaks = 100)
qqnorm(trainCapitalAveS)
```
this step normalized the data and the values that are exactly zero or the same remain the same, which is why we see a flat line in the beginning of the qqnorm plot

## data imputation
```{r}
set.seed(123)
training$capAve <- training$capitalAve
selectNA <- rbinom(nrow(training),size=1,prob = 0.05)==1
training$capAve[selectNA] <- NA

#imput the data and standardize
preObj <- preProcess(training[,-58],method = "knnImpute") #impute based on 10 nearest neigbors
capAve <- predict(preObj,training[,-58])$capAve

#standardize the real data
capAveTrue <- training$capitalAve
capAveTrue <- (capAveTrue - mean(capAveTrue))/sd(capAveTrue)

quantile(capAveTrue - capAve)
quantile(capAveTrue - capAve)[selectNA] #Only those imputed
quantile(capAveTrue - capAve)[!selectNA]
```

Training and test must be processed in the same way
Only use parametes estimated from taining set

### Creating dummy variables
```{r}
inTrain <- createDataPartition(Wage$wage,p=0.7,list = F)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dummy <- dummyVars(wage ~ jobclass,data = training)
head(predict(dummy,newdata = training))
```
### Removing variables with zero variability
```{r}
nzv <- nearZeroVar(training, saveMetrics = T)
nzv
```

If you want to account for higher-degree relationship between the y variable and predictors
```{r}
library(splines)
bsAge <- bs(training$age,df=3)
head(bsAge)
```
```{r}
lm1 <- lm(wage ~ bsAge, data = training)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
testAge <- predict(bsAge,age=testing$age) #getting the variable for the test data w/o seeing other variables
```

with train preProcess = "pca" can be used to 
```{r}
data("spam")
intrain <- createDataPartition(spam$type,p=0.75,list = F)
training <- spam[intrain,]
testing <- spam[-intrain,]
typecolor <- ((spam$type == "spam")*1 + 1)
```

```{r}
prePro <- preProcess(log10(spam[,-58] +1),method = "pca",pcaComp = 2)
spamPC <- predict(prePro,log10(spam[,-58]+1))
plot(spamPC,col=typecolor)
```
```{r}
prePro <- preProcess(log10(training[,-58]+1),method = "pca",pcaComp = 2)
trainPC <- predict(prePro,log10(training[,-58]+1))
modelFit <- train(training$type ~ ., method="glm",data=trainPC)
testPC <- predict(prePro,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
```
alternatively
```{r}
modelFit <- train(training$type ~ ., method = "glm", preProcess = "pca",data = training)
confusionMatrix(testing$type,predict(modelFit,testing))
```
pca type prediction is useful for linear models and transformation such as BoxCox is advisable, however, it makes the interpretation difficult

```{r}
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
```

```{r}
flyashcut <- cut2(training$FlyAsh,g = 2)
agecut <- cut2(training$Age,g=3)
qplot(1:nrow(training),training$CompressiveStrength,geom = "point",color=flyashcut)
```

```{r}
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
features <- colnames(training)
```

```{r}
il <- grep('^IL',features)
featuresIl <- features[il]
prePro <- preProcess(training[,il],method = "pca",pcaComp = 11)
pcaResult <- predict(prePro,training[,il])
```
```{r}
trainingIl <- training[,c(il,1)]
head(trainingIl)
testingIl <- testing[,c(il,1)]
```

```{r}
modelLm <- train(diagnosis ~ ., data = trainingIl, method = "glm")
predictLm <- predict(modelLm,testingIl)
confusionMatrix(testing$diagnosis,predictLm)
```

```{r}
prePro <- preProcess(trainingIl[,-13],method = "pca", pcaComp = 7)
trainPca <- predict(prePro,trainingIl[,-13])
trainPca$diagnosis <- trainingIl$diagnosis
modelPca <- train(diagnosis ~ ., data = trainPca, method = "glm")
testPca <- predict(prePro,testingIl[,-13])
testPca$diagnosis <- testingIl$diagnosis
testResult <- predict(modelPca,testPca)
confusionMatrix(testPca$diagnosis,testResult)
```

Decision trees in R
```{r}
data("iris")
inTrain <- createDataPartition(y=iris$Species,p=0.7,list = F)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
```
Building a decision tree
```{r}
modelFit <- train(Species ~ . , method = 'rpart',data = training)
plot(modelFit$finalModel,uniform = T)
library(rattle)
fancyRpartPlot(modelFit$finalModel)
```

