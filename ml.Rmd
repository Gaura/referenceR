Here is a guide to using caret package in predictive modelling: https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf

It is a useful package that consists of functions that unify predictive models from different packages.
It contains functions to do basic stuff like train test split in R.

Setup
```{r setup}
library(kernlab)
library(caret)
library(ISLR)
library(ggplot2)
library(Hmisc) # cut function for breaking data into groups
```
Creat data split
```{r}
?createDataPartition #shows up other useful functions as well
data("spam")
train <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[train,]
testing <- spam[-train,]
```
This function creates a training model and the performance measured is calculated based on resampling measure bootstrap
```{r}
model <- train(type ~ ., data = training, method = "glm")
model$finalModel # to view the final model
prediction <- predict(model,newdata= testing)
prediction
confusionMatrix(prediction,testing$type)
```
The train function comes with other bunch of arguments that might prove to be useful, for example it has metric argument to evalute the model performance, They are
1. For continous y
      - RMSE (default)
      - R-squared
2. For indicator y
      - Accuracy
      - Kappa
To further control the parameters of the train function, we can use trainControl function
```{r}
?trainControl
args(trainControl)
```
featurePlot in caret package to create a plot of the features
```{r}
data(Wage)
trainSamples <- createDataPartition(Wage$wage,p=0.7,list = FALSE)
trainData <- Wage[trainSamples,]
testData <- Wage[-trainSamples,]
featurePlot(x=trainData[,c("age","education","jobclass")],y=trainData$wage,plot = "pairs")
```
visualize trend, there seems to be positive cor b/w education and wages
```{r}
qp <- qplot(x = age, y = wage, data = trainData, color = education)
qp + geom_smooth(method = "lm",formula = y ~ x)
```
We can break the age into categorical variables to see the relationship between wages and age clearly.
One thing that we can do after the boxplot is to add points on the top of it so that we can see if the number of points are large in each set, otherwise if the points are not plotted we may not know
if the change is real or artificial because of change in sample size
```{r}
cutWage <- cut2(trainData$wage,g=3)
table(cutWage)
p1 <- qplot(cutWage,age,fill=cutWage,data=trainData,geom = c("boxplot"))
p2 <- qplot(cutWage,age,fill=cutWage,data=trainData,geom = c("boxplot","jitter"))
grid.arrange(p1,p2,ncol=2)
```
Now let us see how how the wage classes are distributed among the education categories
```{r}
t1 <- table(cutWage,trainData$education)
t1
prop.table(t1,1) # 1 is margin
```
This shows that 34% of high wage jobs are held by college grads followed by adv degree holders with 30% of the jobs

Let us check the same information visually using density plots
```{r}
qplot(wage,colour=education,data = trainData, geom = "density",ylab = "density")
```
This density plot is like prop.table but along the columns, it shows that adv degree holders have higher density at higher end of wages but their number may not be the highest, it is important to note that density is not the same as the numbers but is proportion within each education category

MAKE YOUR PLOTS ONLY IN THE TRAINING DATA
DO NOT USE THE TEST DATA FOR EXPLORATION
